{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Project 3 in Self Driving Car Nano degree from Udacity\n",
    "\n",
    "The purpose of this project is using deep learning to train a deep neural network to drive a car automously in a  simulator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Cloning Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "- Use the simulator to collect data of good driving behavior\n",
    "- Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "- Train and validate the model with a training and validation set\n",
    "- Test that the model successfully drives around track one without leaving the road\n",
    "- Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric Points\n",
    "\n",
    "Here I will consider the [rubric points](https://review.udacity.com/#!/rubrics/432/view) individually and describe how I addressed each point in my implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files Submitted & Code Quality\n",
    "\n",
    "My project includes the following files:\n",
    "\n",
    "- model.ipynb containing the script to create and train the model, data processing and tuning parameters.\n",
    "- drive.py for driving the car in autonomous mode\n",
    "- model.h5 containing a trained convolution neural network\n",
    "- writeup_report.html or writeup_report.pdf summarizing the results\n",
    "- video.mp4 capturing the simulation running in automonous mode with the selected model.\n",
    "\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing\n",
    "\n",
    "    python drive.py model.h5\n",
    "\n",
    "Due to a problem in my python environment, I create the pipeline in the model.ipynb instead of model.py as required. The model.ipynb file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Model Architecture\n",
    "\n",
    "My model is based on model proposed by the NVIDIA in [this paper](http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf). The NVIDIA model is well-documented and not complicated and has been proven its effectiveness in self driving car control.\n",
    "\n",
    "The NVIDIA model architecture is summarized as follows:\n",
    "\n",
    "Layer        | Description\n",
    "------------ | -------------\n",
    "Input\t| 66x200x3 RGB image\n",
    "Lambda | Normalized\n",
    "Convolution 5x5x24 | valid padding, subsample(2,2), activation ReLU, outputs 31x98x24\n",
    "Convolution 5x5x36 | valid padding, subsample(2,2), activation ReLU, outputs 14x47x36\n",
    "Convolution 5x5x48 | valid padding, subsample(2,2), activation ReLU, outputs 5x22x48\n",
    "Convolution 3x3x64 | valid padding, subsample(2,2), activation ReLU, outputs 3x20x64\n",
    "Convolution 3x3x64 | valid padding, subsample(2,2), activation ReLU, outputs 1x18x64\n",
    "Flatten | outputs 1152\n",
    "Fully connected\t| activation ReLU, outputs 100\n",
    "Fully connected\t| activation ReLU, outputs 50\n",
    "Fully connected\t| activation ReLU, outputs 20\n",
    "Fully connected\t| outputs 1\n",
    "\n",
    "My initial model is modified from NVIDIA model with some modifications as follows:\n",
    "\n",
    "Layer        | Description\n",
    "------------ | -------------\n",
    "**Input**\t| **160x320x3 RGB image**\n",
    "**Lambda** | **Cropping, outputs 75x320x3**\n",
    "Lambda | Normalized, outputs 75x320x3\n",
    "Convolution 5x5x24 | valid padding, subsample(2,2), activation ReLU, outputs 36x158x24\n",
    "Convolution 5x5x36 | valid padding, subsample(2,2), activation ReLU, outputs 16x77x36\n",
    "Convolution 5x5x48 | valid padding, subsample(2,2), activation ReLU, outputs 6x37x48\n",
    "Convolution 3x3x64 | valid padding, subsample(2,2), activation ReLU, outputs 4x35x64\n",
    "Convolution 3x3x64 | valid padding, subsample(2,2), activation ReLU, outputs 2x33x64\n",
    "**Dropout** | **keeping probability 0.5, outputs 2x33x64**\n",
    "Flatten | outputs 4224\n",
    "Fully connected\t| activation ReLU, outputs 100\n",
    "Fully connected\t| activation ReLU, outputs 50\n",
    "Fully connected\t| activation ReLU, outputs 20\n",
    "Fully connected\t| outputs 1\n",
    "\n",
    "Total params: 559,419\n",
    "\n",
    "- My model consisted of a convolution neural network with three 5x5 and 3x3  filter sizes and depths between 24 and 64.\n",
    "- The convolution layers included RELU activations to introduce nonlinearity and downsample 2 times.\n",
    "- The data was normalized in the model using a Keras lambda layer.\n",
    "- Because the captured images have size of 160x320 and include redundant part such as sky and the front part of the car, a Keras lambda layers was added for cropping the redundancy.\n",
    "- The model contained a dropout layer with keeping probability 0.5 in order to reduce overfitting.\n",
    "- The model used an adam optimizer with default learning rate 0.001, so the learning rate was not tuned manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Training Strategy\n",
    "\n",
    "Training data was chosen to keep the vehicle driving on the road. I used a combination of \n",
    "- center lane driving, \n",
    "- recovering from the left and right sides of the road, \n",
    "- driving counter-clockwise to help the model generalized, \n",
    "- flipping the images to help the model generalized, \n",
    "- collecting data from the second track can also help generalize the model\n",
    "\n",
    "For details about how I created the training data, see the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture and Training Documentation\n",
    "\n",
    "#### 1. Solution Design Approach\n",
    "\n",
    "The overall strategy for deriving a model architecture was to use a well-known model that is sucessful in the field of self driving car and then twist model parameters as well as use appropriate image pre-processing and augmentation to the training dataset. The model was trained and validated on different data sets to ensure that the model was not overfitting. The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track.\n",
    "\n",
    "My first step was to use a convolution neural network model similar to the NVIDIA model in [this paper](http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf). I thought this model might be appropriate because the NVIDIA model is well-documented and not complicated and has been proven its effectiveness in self driving car control.\n",
    "\n",
    "Then I focused on image pre-processing methods which including: \n",
    "- Crop the sky (60 pixels) and steering wheel (25 pixels) parts in the image.\n",
    "- Resize the images from 160x320x3 matrix to 66x200x3 matrix, which is the input size of the NVIDIA model. I tested without/with this image processing to see if the resizing affect the performance of the model. After testing, I added a Lambda layer for resizing the image since helped reducing the training time without decreasing the model performance.\n",
    "\n",
    "In order to gauge how well the model was working, I split my image and steering angle data into a training and validation set. I found that my first model had a low mean squared error on the training set but a high mean squared error on the validation set. This implied that the model was overfitting.\n",
    "\n",
    "To combat the overfitting, I modified the model so that the model contains a dropout layer with keeping probability 0.5 in order to reduce overfitting.\n",
    "\n",
    "The final step was to run the simulator to see how well the car was driving around track one. \n",
    "\n",
    "There were a few spots where the vehicle fell off the track. To improve the driving behavior in these cases, I collected more training data in the track one, as well as generate more training data using image augmentation methods (see details in the next part).\n",
    "\n",
    "At the end of the process, the vehicle is able to drive autonomously around the track without leaving the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Final Model Architecture\n",
    "\n",
    "The final model architecture consisted of a convolution neural network with the following layers and layer sizes.\n",
    "\n",
    "Layer        | Description\n",
    "------------ | -------------\n",
    "Input\t| 160x320x3 RGB image\n",
    "Lambda | Cropping, outputs 75x320x3\n",
    "Lambda | Resized, outputs 66x200x3\n",
    "Lambda | Normalized, outputs 66x200x3\n",
    "Convolution 5x5x24 | valid padding, subsample(2,2), activation ReLU, outputs 31x98x24\n",
    "Convolution 5x5x36 | valid padding, subsample(2,2), activation ReLU, outputs 14x47x36\n",
    "Convolution 5x5x48 | valid padding, subsample(2,2), activation ReLU, outputs 5x22x48\n",
    "Convolution 3x3x64 | valid padding, subsample(2,2), activation ReLU, outputs 3x20x64\n",
    "Convolution 3x3x64 | valid padding, subsample(2,2), activation ReLU, outputs 1x18x64\n",
    "Dropout | keeping probability 0.5, outputs 1152, outputs 1x18x64\n",
    "Flatten | outputs 1152\n",
    "Fully connected\t| activation ReLU, outputs 100\n",
    "Fully connected\t| activation ReLU, outputs 50\n",
    "Fully connected\t| activation ReLU, outputs 20\n",
    "Fully connected\t| outputs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Creation of the Training Set & Training Process\n",
    "\n",
    "To capture good driving behavior, I first recorded two laps on track one using center lane driving. Here is an example image of center lane driving on track one:\n",
    "\n",
    "![title](images/center_1.jpg)\n",
    "\n",
    "I then recorded the vehicle recovering from the left side and right sides of the road back to center so that the vehicle would learn how to go back the center of driving from the left side and right sides. These images show what a recovery looks like:\n",
    "\n",
    "![title](images/side_1.jpg)\n",
    "![title](images/side_2.jpg)\n",
    "![title](images/side_3.jpg)\n",
    "\n",
    "To augment the data sat, I also randomly flipped images and angles thinking that this would balance the left turn bias because the tracks are left-turn. For example, here is an image that has then been flipped:\n",
    "\n",
    "![title](images/center_1.jpg)\n",
    "![title](images/center_1_flipped.jpg)\n",
    "\n",
    "I also recorded the vehicle running around the curves only so that the vehicle would learn how to go around the curves.\n",
    "\n",
    "I also recorded the counter-clockwise driving on track one and track two for better model generalization.\n",
    "\n",
    "After the collection process, I had 36,202 number of data points. I then preprocessed this data by cropping the sky and steering wheel parts in the images and resizing the images to the size of 66 pixel height x 200 pixel width to match with the required input shape of the model.\n",
    "\n",
    "I finally randomly shuffled the data set and put 20% of the data into a validation set. \n",
    "\n",
    "I used this training data for training the model. The validation set helped determine if the model was over or under fitting. \n",
    "\n",
    "I used batch generator to create training and validation batches with batch size = 32 to help the training and validation process faster and without out-of-memory problem.\n",
    "\n",
    "I used an adam optimizer so that manually training the learning rate wasn't necessary.\n",
    "\n",
    "The simulation result after first training times was good at the straight road but sometimes the vehicle went of the track. \n",
    "\n",
    "Hence, I continued improve the image augmentation with the left and right cameras. The simulator captured images from three cameras mounted on the car: a center, right and left camera to overcome the issue of recovering from being off-center. I randomly selected one image from three camera and added steering correction if the left or right image was selected as in the lecture. This kind of image augmentation was applied in the training phase only. Image from center camera always selected in the validation phase.\n",
    "\n",
    "Here is images from the center, left, and right cameras:\n",
    "\n",
    "![title](images/center_2.jpg)\n",
    "![title](images/left_2.jpg)\n",
    "![title](images/right_2.jpg)\n",
    "\n",
    "I added a ModelCheckpoint() object to save all the model weights after each epoch of training and tested all models in the simulator with autonomous mode. The ideal number of epochs was 4 to 5 epochs as evidenced by learning curve plotted at the end of training.\n",
    "\n",
    "At the end of the process, the vehicle is able to drive autonomously around the track one without leaving the road.\n",
    "\n",
    "With track two, I repeated above process in order to get more data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_image(img, angle):\n",
    "    \"\"\"\n",
    "    Randomly flip the image and adjust the steering angle.\n",
    "    \"\"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        img = cv2.flip(img, 1)\n",
    "        angle = -angle\n",
    "    return img, angle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and spliting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the driving_log.csv and get paths of images as samples\n",
    "samples = []\n",
    "with open('../../P3_Data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using generator function to compile and train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_image(batch_sample, is_training=False):\n",
    "    \"\"\"\n",
    "    Randomly select an image among the center, left or right images, and adjust the steering angle.\n",
    "    This way, we can teach your model how to steer if the car drifts off to the left or the right.\n",
    "    \"\"\"\n",
    "    if is_training == True:\n",
    "        choice = np.random.choice(3)\n",
    "    else:\n",
    "        choice = 0\n",
    "        \n",
    "    name = '../../P3_Data/IMG/'+batch_sample[choice].split('/')[-1]\n",
    "    image = cv2.imread(name)\n",
    "    steering_center = float(batch_sample[3])\n",
    "\n",
    "    # create adjusted steering measurements for the side camera images\n",
    "    correction = 0.2 # this is a parameter to tune\n",
    "    steering_left = steering_center + correction\n",
    "    steering_right = steering_center - correction\n",
    "\n",
    "    if choice == 0:\n",
    "        return image, steering_center\n",
    "    elif choice == 1:\n",
    "        return image, steering_left\n",
    "    return image, steering_right\n",
    "\n",
    "def generator(samples, batch_size=32, is_training=False):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                image, angle = select_image(batch_sample, is_training=is_training)\n",
    "                images.append(image)\n",
    "                angles.append(angle)\n",
    "\n",
    "            # Get training data\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            \n",
    "            # Randomly flip image if in training mode\n",
    "            if is_training == True:\n",
    "                X_train_augmented, y_train_augmented = [], []\n",
    "                for x, y in zip(X_train, y_train):\n",
    "                    x_augmented, y_augmented = flip_image(x, y)\n",
    "                    X_train_augmented.append(x_augmented)\n",
    "                    y_train_augmented.append(y_augmented)\n",
    "\n",
    "                X_train_augmented = np.array(X_train_augmented)\n",
    "                y_train_augmented = np.array(y_train_augmented)       \n",
    "\n",
    "                yield sklearn.utils.shuffle(X_train_augmented, y_train_augmented)\n",
    "            \n",
    "            else:\n",
    "                yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32, is_training=True)\n",
    "validation_generator = generator(validation_samples, batch_size=32, is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "cropping2d_1 (Cropping2D)        (None, 75, 320, 3)    0           cropping2d_input_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 66, 200, 3)    0           cropping2d_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 66, 200, 3)    0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 98, 24)    1824        lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 47, 36)    21636       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 22, 48)     43248       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 20, 64)     27712       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 18, 64)     36928       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1, 18, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1152)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           115300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phuongpham/anaconda3/anaconda/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1917: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9653/9653 [==============================] - 79s - loss: 0.0361 - val_loss: 0.0181\n",
      "Epoch 2/10\n",
      "9653/9653 [==============================] - 79s - loss: 0.0312 - val_loss: 0.0193\n",
      "Epoch 3/10\n",
      "9653/9653 [==============================] - 78s - loss: 0.0297 - val_loss: 0.0191\n",
      "Epoch 4/10\n",
      "9653/9653 [==============================] - 77s - loss: 0.0299 - val_loss: 0.0176\n",
      "Epoch 5/10\n",
      "9653/9653 [==============================] - 80s - loss: 0.0279 - val_loss: 0.0171\n",
      "Epoch 6/10\n",
      "9653/9653 [==============================] - 79s - loss: 0.0277 - val_loss: 0.0172\n",
      "Epoch 7/10\n",
      "9653/9653 [==============================] - 80s - loss: 0.0291 - val_loss: 0.0192\n",
      "Epoch 8/10\n",
      "9653/9653 [==============================] - 79s - loss: 0.0266 - val_loss: 0.0180\n",
      "Epoch 9/10\n",
      "9653/9653 [==============================] - 77s - loss: 0.0246 - val_loss: 0.0168\n",
      "Epoch 10/10\n",
      "9653/9653 [==============================] - 76s - loss: 0.0242 - val_loss: 0.0153\n",
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn5oUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12227a4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build network architecture \n",
    "# for a regression network (need only 1 neuron at output)\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.backend import tf as ktf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "row, col, ch = 160, 320, 3  # image format\n",
    "INPUT_SHAPE = (row,col,ch)\n",
    "\n",
    "def resize(image):\n",
    "    from keras.backend import tf as ktf   \n",
    "    resized = ktf.image.resize_images(image, (66, 200))\n",
    "    return resized\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "## Set up lambda layers for data preprocessing: \n",
    "\n",
    "# Set up cropping2D layer: cropping (top, bottom) (left, right) pixels \n",
    "model.add(Cropping2D(cropping=((60,25), (0,0)), input_shape=INPUT_SHAPE)) \n",
    "\n",
    "# Add Lambda layer for resizing image (image, height, width, data_format)\n",
    "model.add(Lambda(resize, input_shape=(75, 320, 3), output_shape=(66, 200, 3)))\n",
    "\n",
    "# Add Lambda layer for normalization\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1.0))\n",
    "\n",
    "## Build a Multi-layer feedforward neural network with Keras here.\n",
    "\n",
    "# 1st Layer - Add a convolution layer\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))\n",
    "\n",
    "# 2nd Layer - Add a convolution layer\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))\n",
    "\n",
    "# 3rd Layer - Add a convolution layer\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))\n",
    "\n",
    "# 4th Layer - Add a convolution layer\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "\n",
    "# 5th Layer - Add a convolution layer\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "\n",
    "# 6th Layer - Add a convolution layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 7th Layer - Add a flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# 8th Layer - Add a fully connected layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "# 9th Layer - Add a fully connected layer\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# 10th Layer - Add a fully connected layer\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# 11th Layer - Add a fully connected layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# saves the model weights after each epoch if the validation loss decreased\n",
    "checkpointer = ModelCheckpoint('model-{epoch:02d}.h5',\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=0,\n",
    "                                 save_best_only=False,\n",
    "                                 mode='auto')\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='mse', verbose = 1)\n",
    "# history_object = model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=7, batch_size=128)\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch=len(train_samples), \\\n",
    "                                     validation_data=validation_generator, nb_val_samples=len(validation_samples), \\\n",
    "                                     nb_epoch=10, callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "#model.save('model.h5')\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the network\n",
    "\n",
    "I run the network on the pre-trained model with the following command:\n",
    "\n",
    "    python drive.py model-1.h5\n",
    "    \n",
    "And run the simulator with the Autonomous mode. The output video was recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to the output video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
